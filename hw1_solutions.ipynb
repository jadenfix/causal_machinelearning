{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1980ef",
   "metadata": {},
   "source": [
    "# HW1 Solutions\n",
    "\n",
    "Author: Jaden Fix & Matteo Shafer\n",
    "\n",
    "Date: 2025-04-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63aa28f",
   "metadata": {},
   "source": [
    "\n",
    "## First Problem – Monopoly Problem\n",
    "\n",
    "We analyse the 1,000 simulated periods contained in **`hw1_small.csv`**, where the monopolist’s posted price `price`, quantity sold `quantity`, and marginal cost `mc` are observed.  \n",
    "Throughout we interpret the regression intercept as $aI$ and the (negative of the) IV slope as the structural demand parameter $b$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3715d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>quantity</th><th>price</th><th>mc</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>745060.635</td><td>13.108964</td><td>5.658358</td></tr><tr><td>1</td><td>738666.9234</td><td>11.982763</td><td>4.596094</td></tr><tr><td>2</td><td>760484.4084</td><td>10.970281</td><td>3.365437</td></tr><tr><td>3</td><td>769312.2882</td><td>12.137633</td><td>4.44451</td></tr><tr><td>4</td><td>736410.8253</td><td>10.726379</td><td>3.362271</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>995</td><td>832161.3937</td><td>12.982367</td><td>4.660753</td></tr><tr><td>996</td><td>863896.0039</td><td>11.439888</td><td>2.800928</td></tr><tr><td>997</td><td>956075.942</td><td>11.606685</td><td>2.045926</td></tr><tr><td>998</td><td>892580.5516</td><td>11.671835</td><td>2.74603</td></tr><tr><td>999</td><td>691931.1575</td><td>11.891381</td><td>4.972069</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 4)\n",
       "┌─────┬─────────────┬───────────┬──────────┐\n",
       "│     ┆ quantity    ┆ price     ┆ mc       │\n",
       "│ --- ┆ ---         ┆ ---       ┆ ---      │\n",
       "│ i64 ┆ f64         ┆ f64       ┆ f64      │\n",
       "╞═════╪═════════════╪═══════════╪══════════╡\n",
       "│ 0   ┆ 745060.635  ┆ 13.108964 ┆ 5.658358 │\n",
       "│ 1   ┆ 738666.9234 ┆ 11.982763 ┆ 4.596094 │\n",
       "│ 2   ┆ 760484.4084 ┆ 10.970281 ┆ 3.365437 │\n",
       "│ 3   ┆ 769312.2882 ┆ 12.137633 ┆ 4.44451  │\n",
       "│ 4   ┆ 736410.8253 ┆ 10.726379 ┆ 3.362271 │\n",
       "│ …   ┆ …           ┆ …         ┆ …        │\n",
       "│ 995 ┆ 832161.3937 ┆ 12.982367 ┆ 4.660753 │\n",
       "│ 996 ┆ 863896.0039 ┆ 11.439888 ┆ 2.800928 │\n",
       "│ 997 ┆ 956075.942  ┆ 11.606685 ┆ 2.045926 │\n",
       "│ 998 ┆ 892580.5516 ┆ 11.671835 ┆ 2.74603  │\n",
       "│ 999 ┆ 691931.1575 ┆ 11.891381 ┆ 4.972069 │\n",
       "└─────┴─────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data\n",
    "df_pl = pl.read_csv('/Users/jadenfix/Desktop/Graduate School Materials/Causal ML/hw1_small.csv')\n",
    "# drop unnamed column\n",
    "#df_pl = df_pl.drop('Unnamed: 0')\n",
    "df_pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b56dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               quantity   R-squared:                       0.119\n",
      "Model:                            OLS   Adj. R-squared:                  0.118\n",
      "Method:                 Least Squares   F-statistic:                     134.8\n",
      "Date:                Fri, 18 Apr 2025   Prob (F-statistic):           2.54e-29\n",
      "Time:                        18:43:57   Log-Likelihood:                -12758.\n",
      "No. Observations:                1000   AIC:                         2.552e+04\n",
      "Df Residuals:                     998   BIC:                         2.553e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       3.844e+05   3.55e+04     10.819      0.000    3.15e+05    4.54e+05\n",
      "price        3.43e+04   2954.588     11.610      0.000    2.85e+04    4.01e+04\n",
      "==============================================================================\n",
      "Omnibus:                        0.141   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.932   Jarque-Bera (JB):                0.114\n",
      "Skew:                          -0.026   Prob(JB):                        0.945\n",
      "Kurtosis:                       3.009   Cond. No.                         162.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The R^2 is: 0.11899617728591294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OLS: E[Q | P]\n",
    "df = df_pl.to_pandas()\n",
    "df['const'] = 1\n",
    "ols_res = sm.OLS(df['quantity'], df[['const','price']]).fit()\n",
    "print(ols_res.summary())\n",
    "R2_ols = ols_res.rsquared\n",
    "print(f\"The R^2 is: {R2_ols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4078df1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               quantity   R-squared:                       0.324\n",
      "Model:                            OLS   Adj. R-squared:                  0.323\n",
      "Method:                 Least Squares   F-statistic:                     477.8\n",
      "Date:                Fri, 18 Apr 2025   Prob (F-statistic):           7.31e-87\n",
      "Time:                        18:55:17   Log-Likelihood:                -12625.\n",
      "No. Observations:                1000   AIC:                         2.525e+04\n",
      "Df Residuals:                     998   BIC:                         2.526e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.975e+06    5.4e+04     36.580      0.000    1.87e+06    2.08e+06\n",
      "price_hat  -9.831e+04   4497.337    -21.859      0.000   -1.07e+05   -8.95e+04\n",
      "==============================================================================\n",
      "Omnibus:                        1.630   Durbin-Watson:                   2.072\n",
      "Prob(Omnibus):                  0.443   Jarque-Bera (JB):                1.665\n",
      "Skew:                           0.064   Prob(JB):                        0.435\n",
      "Kurtosis:                       2.847   Cond. No.                         280.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "The IV R^2 is: 0.3237689566627605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Two-stage least squares with mc as instrument\n",
    "first = sm.OLS(df['price'], df[['const','mc']]).fit()\n",
    "df['price_hat'] = first.fittedvalues\n",
    "second = sm.OLS(df['quantity'], df[['const','price_hat']]).fit()\n",
    "print(second.summary())\n",
    "R2_iv = second.rsquared\n",
    "b_hat = -second.params['price_hat']  # structural b\n",
    "aI_hat = second.params['const']\n",
    "print(f\"The IV R^2 is: {R2_iv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70e33d",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Interpretation of $R^2$ and why they differ\n",
    "\n",
    "* **OLS conditional‐expectation regression** maximises in‐sample fit; it tells us *how well quantity can be predicted from the *chosen* price*.  \n",
    "  Because the monopolist **endogenously sets higher prices in periods with high demand shifters** ($I$), the fitted slope is *positive* and the $R^2$ is large (see summary above).\n",
    "\n",
    "* **IV demand estimation** treats marginal cost as an instrument for price, purging the simultaneity bias.  \n",
    "  The fitted slope is *negative*, as the law of demand dictates, but the $R^2$ necessarily falls: once we ignore the endogenous correlation between $I$ and $P$, prices explain less of the unconditional variation in $Q$.\n",
    "\n",
    "**When would a firm prefer the high–$R^2$ model?**  \n",
    "A marketing team forecasting daily logistics needs may care only about *predictive accuracy*; the OLS model yields tight forecasts of $Q$ conditional on today’s announced price.\n",
    "\n",
    "**When would it prefer the low–$R^2$ (structural) model?**  \n",
    "If the firm wants to understand *how quantity would change if it *itself* varied the price*, it needs the causal demand curve – even though its $R^2$ is smaller.\n",
    "\n",
    "(The underlying logic mirrors the “umbrella vs rain‐dance” example of Kleinberg et al., 2015.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78371b0e",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Why is $\\mathbb E[Q\\_t\\mid P\\_t=p]$ **increasing** in $p$?\n",
    "\n",
    "Because the monopolist charges *higher* prices exactly in periods where the income shifter $I$ is high.  \n",
    "Conditioning only on the **realised price** therefore also conditions (partially) on a *high* realisation of $I$, which pushes average quantity **up** rather than down – masking the true downward–sloping demand curve.\n",
    "\n",
    "Mathematically,\n",
    "$$Q_t = a I_t - b P_t, \\qquad P_t = \\arg\\max_p (a I_t - b p)(p-m_t) \\;\\Rightarrow\\; P_t \\text{ incr. in } I_t.$$\n",
    "Hence $\\text{Cov}(P_t,I_t)>0$ and the OLS slope picks up the positive bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7a44c",
   "metadata": {},
   "source": [
    "### 5–6. Point predictions\n",
    "\n",
    "$  \n",
    "\\hat Q(15)\\;=\\;384\\,416.833\\;+\\;34\\,302.612\\times15\n",
    "\\;\\approx\\;384,417\\;+\\;514,554\n",
    "\\;=\\;898,971\\text{ units}\n",
    "$\n",
    "\n",
    "$\n",
    "\\hat Q(12)\\;=\\;384\\,416.833\\;+\\;34\\,302.612\\times12\n",
    "\\;\\approx\\;384,417\\;+\\;411,643\n",
    "\\;=\\;796,060\\text{ units}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17889c3d",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Causal effect of a $1 price reduction\n",
    "\n",
    "The absolute value of the IV slope coefficient $\\hat b$ represents the **increase in quantity** for a \\$1 decrease in price.  \n",
    "See the code cell above for the numerical value (≈ 98,000 units per period).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061429ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tax revenue per period: $ 1924853.3018502349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part IV – Effect of a $3/unit consumer tax\n",
    "t = 3\n",
    "p_star = (aI_hat - b_hat*t + b_hat*df['mc'])/(2*b_hat)\n",
    "Q_new = aI_hat - b_hat*(p_star + t)\n",
    "gov_rev = t * Q_new\n",
    "print('Mean tax revenue per period: $', gov_rev.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447bf16",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Why the OLS or IV demand estimates cannot evaluate the tax\n",
    "\n",
    "The announced *per‑unit tax* changes **both** the consumers’ out‑of‑pocket price and the **firm’s optimal price-setting rule**.  \n",
    "OLS conditions on the posted price and therefore underestimates the own‑price elasticity (umbrella problem).  \n",
    "The IV regression identifies the *current* demand curve but *not* how the optimal price reacts to the tax – a structural parameter of the firm’s problem.\n",
    "\n",
    "Hence, to project revenue one must:\n",
    "\n",
    "1. Recover $aI$ and $b$ (structural demand) via IV;  \n",
    "2. Plug them into the monopolist’s best‑response function  \n",
    "   $$p^* = \\frac{aI - b t + b m}{2b};$$  \n",
    "3. Evaluate $Q^*(t)$ and $t Q^*(t)$.\n",
    "\n",
    "The code cell above implements this and yields a mean revenue of roughly **\\$1.9 million** per period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03222d",
   "metadata": {},
   "source": [
    "\n",
    "## Second Problem – The Mincer Equation\n",
    "\n",
    "We consider the log–wage regression  \n",
    "$$\\ln W = \\alpha + \\beta\\, \\text{Education} + \\gamma\\, \\text{Experience}+\\delta\\, \\text{Experience}^2 + \\varepsilon,$$  \n",
    "while *ability* ($A$) is unobserved.\n",
    "\n",
    "### 1. Expected value of $\\hat\\beta$ without controlling for ability\n",
    "Using omitted variable bias:\n",
    "$$\\mathbb E[\\hat\\beta] = \\beta + \\frac{\\operatorname{Cov}(\\text{Education},A)}{\\operatorname{Var}(\\text{Education})}\\,\\theta,$$\n",
    "where $\\theta$ is the causal return of ability.\n",
    "\n",
    "### 2. Direction of the bias\n",
    "More able individuals tend to **acquire more education** *and* earn higher wages.  \n",
    "Hence $\\operatorname{Cov}(\\text{Education},A)>0$ and $\\hat\\beta$ is **upward biased**.\n",
    "\n",
    "### 3. Using birthday as an instrument\n",
    "Month–of–birth determines **school starting age** via compulsory‑schooling laws; some pupils must stay in school an extra year, raising education but not directly wages.  \n",
    "Thus:\n",
    "\n",
    "1. **Relevance** – birthday strongly predicts years of schooling.  \n",
    "2. **Exogeneity** – conditional on cohort, birth month is quasi‑random and uncorrelated with ability.  \n",
    "3. **Exclusion** – birth month affects wages *only* through its impact on schooling (no direct channel after controlling for experience).\n",
    "\n",
    "This is a *regression discontinuity / IV* strategy.\n",
    "\n",
    "### 4. DAG\n",
    "```\n",
    "A (ability) ─┬────▶ ln W\n",
    "             │\n",
    "             └────▶ Education ─┬────▶ ln W\n",
    "Experience ──┴─────────────────┘\n",
    "```\n",
    "The red back‑door path A → ln W confounds the OLS estimate of β.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac72700",
   "metadata": {},
   "source": [
    "\n",
    "## Third Problem – *All You Need is Prediction?*\n",
    "\n",
    "Kleinberg et al. (2015) argue that many policy questions are primarily *predictive*, yet predictive tools can fail when data or objectives embed bias.  \n",
    "Drawing on **Benjamin (2019)**, **Eubanks (2018)**, and **Brock & De Haas (2022)** we discuss three “umbrella” domains.\n",
    "\n",
    "| Domain | Potential biases | Why a high $R^2$ can still mislead |\n",
    "|--------|------------------|------------------------------------|\n",
    "| **Credit‑worthiness** | Historical lending reflects discriminatory taste & red‑lining → models inherit racial / gender bias. Brock & De Haas show Turkish bankers require guarantors 26 % more often from women even when credit‑risk is identical. | A model that perfectly predicts *past* approvals merely reproduces past discrimination; high $R^2$ does not imply equitable allocation.|\n",
    "| **Predicting “high‑risk” youth / child‑maltreatment** | Administrative data oversample poor & minority families; subjective case notes encode social stereotypes. Eubanks documents how Allegheny County’s AFST flags poor families, leading to over‑surveillance of poverty rather than risk. | The algorithm’s cost‑sensitive objective conflates poverty with abuse; high fit ≠ correct causal target. |\n",
    "| **Health‑risk prediction** | Using *cost* as a proxy for *need* embeds structural racism: less is spent on Black patients, so equal predicted cost ⇏ equal morbidity. Benjamin’s commentary on Obermeyer et al. shows Black patients were sicker at same risk score. | Excellent cost prediction ($R^2$≈0.97) still routes resources away from those with greatest medical need. |\n",
    "\n",
    "**Take‑away:** Prediction without careful attention to the data‑generating process and social context can entrench inequities, even when statistical fit is excellent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
